{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0278,
     "end_time": "2021-01-10T19:05:34.373999",
     "exception": false,
     "start_time": "2021-01-10T19:05:34.346199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**This notebook is an exercise in the [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/categorical-variables).**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024785,
     "end_time": "2021-01-10T19:05:34.423916",
     "exception": false,
     "start_time": "2021-01-10T19:05:34.399131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "By encoding **categorical variables**, you'll obtain your best results thus far!\n",
    "\n",
    "# Setup\n",
    "\n",
    "The questions below will give you feedback on your work. Run the following cell to set up the feedback system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:34.478375Z",
     "iopub.status.busy": "2021-01-10T19:05:34.477573Z",
     "iopub.status.idle": "2021-01-10T19:05:34.539245Z",
     "shell.execute_reply": "2021-01-10T19:05:34.538547Z"
    },
    "papermill": {
     "duration": 0.090428,
     "end_time": "2021-01-10T19:05:34.539378",
     "exception": false,
     "start_time": "2021-01-10T19:05:34.448950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# Set up code checking\n",
    "import os\n",
    "if not os.path.exists(\"../input/train.csv\"):\n",
    "    os.symlink(\"../input/home-data-for-ml-course/train.csv\", \"../input/train.csv\")  \n",
    "    os.symlink(\"../input/home-data-for-ml-course/test.csv\", \"../input/test.csv\") \n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.ml_intermediate.ex3 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025303,
     "end_time": "2021-01-10T19:05:34.592038",
     "exception": false,
     "start_time": "2021-01-10T19:05:34.566735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this exercise, you will work with data from the [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/c/home-data-for-ml-course). \n",
    "\n",
    "![Ames Housing dataset image](https://i.imgur.com/lTJVG4e.png)\n",
    "\n",
    "Run the next code cell without changes to load the training and validation sets in `X_train`, `X_valid`, `y_train`, and `y_valid`.  The test set is loaded in `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:34.647850Z",
     "iopub.status.busy": "2021-01-10T19:05:34.646830Z",
     "iopub.status.idle": "2021-01-10T19:05:36.019851Z",
     "shell.execute_reply": "2021-01-10T19:05:36.019203Z"
    },
    "papermill": {
     "duration": 1.402183,
     "end_time": "2021-01-10T19:05:36.019973",
     "exception": false,
     "start_time": "2021-01-10T19:05:34.617790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X = pd.read_csv('../input/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('../input/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll drop columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "cols_with_missing = cols_with_missing + [col for col in X_test.columns if X_test[col].isnull().any()]\n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025617,
     "end_time": "2021-01-10T19:05:36.072269",
     "exception": false,
     "start_time": "2021-01-10T19:05:36.046652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use the next code cell to print the first five rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:36.144849Z",
     "iopub.status.busy": "2021-01-10T19:05:36.144059Z",
     "iopub.status.idle": "2021-01-10T19:05:36.158353Z",
     "shell.execute_reply": "2021-01-10T19:05:36.158871Z"
    },
    "papermill": {
     "duration": 0.060466,
     "end_time": "2021-01-10T19:05:36.159026",
     "exception": false,
     "start_time": "2021-01-10T19:05:36.098560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>20</td>\n",
       "      <td>11694</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>20</td>\n",
       "      <td>6600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30</td>\n",
       "      <td>13360</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>20</td>\n",
       "      <td>13265</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>13704</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>468</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass  LotArea Street LotShape LandContour LotConfig LandSlope  \\\n",
       "Id                                                                         \n",
       "619          20    11694   Pave      Reg         Lvl    Inside       Gtl   \n",
       "871          20     6600   Pave      Reg         Lvl    Inside       Gtl   \n",
       "93           30    13360   Pave      IR1         HLS    Inside       Gtl   \n",
       "818          20    13265   Pave      IR1         Lvl   CulDSac       Gtl   \n",
       "303          20    13704   Pave      IR1         Lvl    Corner       Gtl   \n",
       "\n",
       "    Neighborhood Condition1 Condition2  ... WoodDeckSF OpenPorchSF  \\\n",
       "Id                                      ...                          \n",
       "619      NridgHt       Norm       Norm  ...          0         108   \n",
       "871        NAmes       PosN       Norm  ...          0           0   \n",
       "93       Crawfor       Norm       Norm  ...          0           0   \n",
       "818      Mitchel       Norm       Norm  ...        150          59   \n",
       "303      CollgCr       Norm       Norm  ...        468          81   \n",
       "\n",
       "     EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea MiscVal MoSold YrSold  \\\n",
       "Id                                                                           \n",
       "619              0          0          260         0       0      7   2007   \n",
       "871              0          0            0         0       0      8   2009   \n",
       "93              44          0            0         0       0      8   2009   \n",
       "818              0          0            0         0       0      7   2008   \n",
       "303              0          0            0         0       0      1   2006   \n",
       "\n",
       "    SaleCondition  \n",
       "Id                 \n",
       "619       Partial  \n",
       "871        Normal  \n",
       "93         Normal  \n",
       "818        Normal  \n",
       "303        Normal  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026102,
     "end_time": "2021-01-10T19:05:36.211907",
     "exception": false,
     "start_time": "2021-01-10T19:05:36.185805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Notice that the dataset contains both numerical and categorical variables.  You'll need to encode the categorical data before training a model.\n",
    "\n",
    "To compare different models, you'll use the same `score_dataset()` function from the tutorial.  This function reports the [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) from a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:36.268287Z",
     "iopub.status.busy": "2021-01-10T19:05:36.267659Z",
     "iopub.status.idle": "2021-01-10T19:05:36.503938Z",
     "shell.execute_reply": "2021-01-10T19:05:36.504542Z"
    },
    "papermill": {
     "duration": 0.266121,
     "end_time": "2021-01-10T19:05:36.504700",
     "exception": false,
     "start_time": "2021-01-10T19:05:36.238579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026286,
     "end_time": "2021-01-10T19:05:36.557786",
     "exception": false,
     "start_time": "2021-01-10T19:05:36.531500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 1: Drop columns with categorical data\n",
    "\n",
    "You'll get started with the most straightforward approach.  Use the code cell below to preprocess the data in `X_train` and `X_valid` to remove columns with categorical data.  Set the preprocessed DataFrames to `drop_X_train` and `drop_X_valid`, respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:36.615678Z",
     "iopub.status.busy": "2021-01-10T19:05:36.614809Z",
     "iopub.status.idle": "2021-01-10T19:05:36.629875Z",
     "shell.execute_reply": "2021-01-10T19:05:36.630590Z"
    },
    "papermill": {
     "duration": 0.045935,
     "end_time": "2021-01-10T19:05:36.630735",
     "exception": false,
     "start_time": "2021-01-10T19:05:36.584800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 2, \"failureMessage\": \"`drop_X_train` should have 33 columns.\", \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_Drop\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#cc3333\">Incorrect:</span> `drop_X_train` should have 33 columns."
      ],
      "text/plain": [
       "Incorrect: `drop_X_train` should have 33 columns."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fill in the lines below: drop columns in training and validation data\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Check your answers\n",
    "step_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:36.690077Z",
     "iopub.status.busy": "2021-01-10T19:05:36.689118Z",
     "iopub.status.idle": "2021-01-10T19:05:36.693601Z",
     "shell.execute_reply": "2021-01-10T19:05:36.692904Z"
    },
    "papermill": {
     "duration": 0.035001,
     "end_time": "2021-01-10T19:05:36.693720",
     "exception": false,
     "start_time": "2021-01-10T19:05:36.658719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_1.hint()\n",
    "#step_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02762,
     "end_time": "2021-01-10T19:05:36.749403",
     "exception": false,
     "start_time": "2021-01-10T19:05:36.721783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Run the next code cell to get the MAE for this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:36.812769Z",
     "iopub.status.busy": "2021-01-10T19:05:36.810326Z",
     "iopub.status.idle": "2021-01-10T19:05:37.795658Z",
     "shell.execute_reply": "2021-01-10T19:05:37.794756Z"
    },
    "papermill": {
     "duration": 1.018218,
     "end_time": "2021-01-10T19:05:37.795776",
     "exception": false,
     "start_time": "2021-01-10T19:05:36.777558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "18934.51899543379\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028873,
     "end_time": "2021-01-10T19:05:37.853552",
     "exception": false,
     "start_time": "2021-01-10T19:05:37.824679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before jumping into label encoding, we'll investigate the dataset.  Specifically, we'll look at the `'Condition2'` column.  The code cell below prints the unique entries in both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:37.918190Z",
     "iopub.status.busy": "2021-01-10T19:05:37.917501Z",
     "iopub.status.idle": "2021-01-10T19:05:37.921045Z",
     "shell.execute_reply": "2021-01-10T19:05:37.921802Z"
    },
    "papermill": {
     "duration": 0.039479,
     "end_time": "2021-01-10T19:05:37.921964",
     "exception": false,
     "start_time": "2021-01-10T19:05:37.882485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029841,
     "end_time": "2021-01-10T19:05:37.982173",
     "exception": false,
     "start_time": "2021-01-10T19:05:37.952332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 2: Label encoding\n",
    "\n",
    "### Part A\n",
    "\n",
    "If you now write code to: \n",
    "- fit a label encoder to the training data, and then \n",
    "- use it to transform both the training and validation data, \n",
    "\n",
    "you'll get an error.  Can you see why this is the case?  (_You'll need  to use the above output to answer this question._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:38.045714Z",
     "iopub.status.busy": "2021-01-10T19:05:38.044995Z",
     "iopub.status.idle": "2021-01-10T19:05:38.051092Z",
     "shell.execute_reply": "2021-01-10T19:05:38.051707Z"
    },
    "papermill": {
     "duration": 0.039617,
     "end_time": "2021-01-10T19:05:38.051860",
     "exception": false,
     "start_time": "2021-01-10T19:05:38.012243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 4, \"questionId\": \"2.1_LabelA\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct:</span> \n",
       "\n",
       "Fitting a label encoder to a column in the training data creates a corresponding integer-valued label for each unique value **that appears in the training data**. In the case that the validation data contains values that don't also appear in the training data, the encoder will throw an error, because these values won't have an integer assigned to them.  Notice that the `'Condition2'` column in the validation data contains the values `'RRAn'` and `'RRNn'`, but these don't appear in the training data -- thus, if we try to use a label encoder with scikit-learn, the code will throw an error."
      ],
      "text/plain": [
       "Correct: \n",
       "\n",
       "Fitting a label encoder to a column in the training data creates a corresponding integer-valued label for each unique value **that appears in the training data**. In the case that the validation data contains values that don't also appear in the training data, the encoder will throw an error, because these values won't have an integer assigned to them.  Notice that the `'Condition2'` column in the validation data contains the values `'RRAn'` and `'RRNn'`, but these don't appear in the training data -- thus, if we try to use a label encoder with scikit-learn, the code will throw an error."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "step_2.a.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:38.118206Z",
     "iopub.status.busy": "2021-01-10T19:05:38.117569Z",
     "iopub.status.idle": "2021-01-10T19:05:38.120696Z",
     "shell.execute_reply": "2021-01-10T19:05:38.120065Z"
    },
    "papermill": {
     "duration": 0.038347,
     "end_time": "2021-01-10T19:05:38.120819",
     "exception": false,
     "start_time": "2021-01-10T19:05:38.082472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#step_2.a.hint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039489,
     "end_time": "2021-01-10T19:05:38.192062",
     "exception": false,
     "start_time": "2021-01-10T19:05:38.152573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is a common problem that you'll encounter with real-world data, and there are many approaches to fixing this issue.  For instance, you can write a custom label encoder to deal with new categories.  The simplest approach, however, is to drop the problematic categorical columns.  \n",
    "\n",
    "Run the code cell below to save the problematic columns to a Python list `bad_label_cols`.  Likewise, columns that can be safely label encoded are stored in `good_label_cols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:38.268898Z",
     "iopub.status.busy": "2021-01-10T19:05:38.268170Z",
     "iopub.status.idle": "2021-01-10T19:05:38.271575Z",
     "shell.execute_reply": "2021-01-10T19:05:38.272397Z"
    },
    "papermill": {
     "duration": 0.049891,
     "end_time": "2021-01-10T19:05:38.272570",
     "exception": false,
     "start_time": "2021-01-10T19:05:38.222679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be label encoded: ['Street', 'LotShape', 'LandContour', 'LotConfig', 'BldgType', 'HouseStyle', 'ExterQual', 'CentralAir', 'PavedDrive', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['RoofMatl', 'Condition1', 'ExterCond', 'Condition2', 'Neighborhood', 'RoofStyle', 'LandSlope', 'Heating', 'Foundation', 'HeatingQC']\n"
     ]
    }
   ],
   "source": [
    "# All categorical columns\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely label encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_train[col]) == set(X_valid[col])]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030704,
     "end_time": "2021-01-10T19:05:38.335266",
     "exception": false,
     "start_time": "2021-01-10T19:05:38.304562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Part B\n",
    "\n",
    "Use the next code cell to label encode the data in `X_train` and `X_valid`.  Set the preprocessed DataFrames to `label_X_train` and `label_X_valid`, respectively.  \n",
    "- We have provided code below to drop the categorical columns in `bad_label_cols` from the dataset. \n",
    "- You should label encode the categorical columns in `good_label_cols`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:38.401981Z",
     "iopub.status.busy": "2021-01-10T19:05:38.401330Z",
     "iopub.status.idle": "2021-01-10T19:05:38.425090Z",
     "shell.execute_reply": "2021-01-10T19:05:38.425604Z"
    },
    "papermill": {
     "duration": 0.058453,
     "end_time": "2021-01-10T19:05:38.425753",
     "exception": false,
     "start_time": "2021-01-10T19:05:38.367300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 2, \"failureMessage\": \"`label_X_train` should have 45 columns.\", \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2.2_LabelB\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#cc3333\">Incorrect:</span> `label_X_train` should have 45 columns."
      ],
      "text/plain": [
       "Incorrect: `label_X_train` should have 45 columns."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply label encoder \n",
    "label_encoder = LabelEncoder()\n",
    "for col in good_label_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "    \n",
    "# Check your answer\n",
    "step_2.b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:38.495545Z",
     "iopub.status.busy": "2021-01-10T19:05:38.494770Z",
     "iopub.status.idle": "2021-01-10T19:05:38.497208Z",
     "shell.execute_reply": "2021-01-10T19:05:38.497666Z"
    },
    "papermill": {
     "duration": 0.039263,
     "end_time": "2021-01-10T19:05:38.497804",
     "exception": false,
     "start_time": "2021-01-10T19:05:38.458541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_2.b.hint()\n",
    "#step_2.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032163,
     "end_time": "2021-01-10T19:05:38.562507",
     "exception": false,
     "start_time": "2021-01-10T19:05:38.530344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Run the next code cell to get the MAE for this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:38.636792Z",
     "iopub.status.busy": "2021-01-10T19:05:38.636086Z",
     "iopub.status.idle": "2021-01-10T19:05:39.739610Z",
     "shell.execute_reply": "2021-01-10T19:05:39.738982Z"
    },
    "papermill": {
     "duration": 1.144078,
     "end_time": "2021-01-10T19:05:39.739724",
     "exception": false,
     "start_time": "2021-01-10T19:05:38.595646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Label Encoding):\n",
      "18232.20285958904\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 2 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033428,
     "end_time": "2021-01-10T19:05:39.806844",
     "exception": false,
     "start_time": "2021-01-10T19:05:39.773416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So far, you've tried two different approaches to dealing with categorical variables.  And, you've seen that encoding categorical data yields better results than removing columns from the dataset.\n",
    "\n",
    "Soon, you'll try one-hot encoding.  Before then, there's one additional topic we need to cover.  Begin by running the next code cell without changes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:39.882251Z",
     "iopub.status.busy": "2021-01-10T19:05:39.881406Z",
     "iopub.status.idle": "2021-01-10T19:05:39.892554Z",
     "shell.execute_reply": "2021-01-10T19:05:39.891930Z"
    },
    "papermill": {
     "duration": 0.052201,
     "end_time": "2021-01-10T19:05:39.892670",
     "exception": false,
     "start_time": "2021-01-10T19:05:39.840469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034004,
     "end_time": "2021-01-10T19:05:39.961154",
     "exception": false,
     "start_time": "2021-01-10T19:05:39.927150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 3: Investigating cardinality\n",
    "\n",
    "### Part A\n",
    "\n",
    "The output above shows, for each column with categorical data, the number of unique values in the column.  For instance, the `'Street'` column in the training data has two unique values: `'Grvl'` and `'Pave'`, corresponding to a gravel road and a paved road, respectively.\n",
    "\n",
    "We refer to the number of unique entries of a categorical variable as the **cardinality** of that categorical variable.  For instance, the `'Street'` variable has cardinality 2.\n",
    "\n",
    "Use the output above to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:40.038655Z",
     "iopub.status.busy": "2021-01-10T19:05:40.037563Z",
     "iopub.status.idle": "2021-01-10T19:05:40.044271Z",
     "shell.execute_reply": "2021-01-10T19:05:40.043678Z"
    },
    "papermill": {
     "duration": 0.048769,
     "end_time": "2021-01-10T19:05:40.044390",
     "exception": false,
     "start_time": "2021-01-10T19:05:39.995621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"3.1_CardinalityA\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fill in the line below: How many categorical variables in the training data\n",
    "# have cardinality greater than 10?\n",
    "high_cardinality_numcols = 3\n",
    "# Fill in the line below: How many columns are needed to one-hot encode the \n",
    "# 'Neighborhood' variable in the training data?\n",
    "num_cols_neighborhood = len(X_train['Neighborhood'].unique())\n",
    "\n",
    "# Check your answers\n",
    "step_3.a.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:40.120536Z",
     "iopub.status.busy": "2021-01-10T19:05:40.119509Z",
     "iopub.status.idle": "2021-01-10T19:05:40.123118Z",
     "shell.execute_reply": "2021-01-10T19:05:40.123614Z"
    },
    "papermill": {
     "duration": 0.043468,
     "end_time": "2021-01-10T19:05:40.123776",
     "exception": false,
     "start_time": "2021-01-10T19:05:40.080308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_3.a.hint()\n",
    "#step_3.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044726,
     "end_time": "2021-01-10T19:05:40.207999",
     "exception": false,
     "start_time": "2021-01-10T19:05:40.163273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Part B\n",
    "\n",
    "For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset.  For this reason, we typically will only one-hot encode columns with relatively low cardinality.  Then, high cardinality columns can either be dropped from the dataset, or we can use label encoding.\n",
    "\n",
    "As an example, consider a dataset with 10,000 rows, and containing one categorical column with 100 unique entries.  \n",
    "- If this column is replaced with the corresponding one-hot encoding, how many entries are added to the dataset?  \n",
    "- If we instead replace the column with the label encoding, how many entries are added?  \n",
    "\n",
    "Use your answers to fill in the lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:40.298791Z",
     "iopub.status.busy": "2021-01-10T19:05:40.297699Z",
     "iopub.status.idle": "2021-01-10T19:05:40.306839Z",
     "shell.execute_reply": "2021-01-10T19:05:40.307404Z"
    },
    "papermill": {
     "duration": 0.058325,
     "end_time": "2021-01-10T19:05:40.307599",
     "exception": false,
     "start_time": "2021-01-10T19:05:40.249274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"3.2_CardinalityB\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fill in the line below: How many entries are added to the dataset by \n",
    "# replacing the column with a one-hot encoding?\n",
    "OH_entries_added = 1e4*100 - 1e4\n",
    "\n",
    "# Fill in the line below: How many entries are added to the dataset by\n",
    "# replacing the column with a label encoding?\n",
    "label_entries_added = 0\n",
    "\n",
    "# Check your answers\n",
    "step_3.b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:40.390955Z",
     "iopub.status.busy": "2021-01-10T19:05:40.389912Z",
     "iopub.status.idle": "2021-01-10T19:05:40.395207Z",
     "shell.execute_reply": "2021-01-10T19:05:40.394538Z"
    },
    "papermill": {
     "duration": 0.045522,
     "end_time": "2021-01-10T19:05:40.395324",
     "exception": false,
     "start_time": "2021-01-10T19:05:40.349802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_3.b.hint()\n",
    "#step_3.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036575,
     "end_time": "2021-01-10T19:05:40.468732",
     "exception": false,
     "start_time": "2021-01-10T19:05:40.432157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, you'll experiment with one-hot encoding.  But, instead of encoding all of the categorical variables in the dataset, you'll only create a one-hot encoding for columns with cardinality less than 10.\n",
    "\n",
    "Run the code cell below without changes to set `low_cardinality_cols` to a Python list containing the columns that will be one-hot encoded.  Likewise, `high_cardinality_cols` contains a list of categorical columns that will be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:40.546074Z",
     "iopub.status.busy": "2021-01-10T19:05:40.545383Z",
     "iopub.status.idle": "2021-01-10T19:05:40.558308Z",
     "shell.execute_reply": "2021-01-10T19:05:40.557758Z"
    },
    "papermill": {
     "duration": 0.052924,
     "end_time": "2021-01-10T19:05:40.558449",
     "exception": false,
     "start_time": "2021-01-10T19:05:40.505525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['Street', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'PavedDrive', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Neighborhood']\n"
     ]
    }
   ],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037063,
     "end_time": "2021-01-10T19:05:40.633386",
     "exception": false,
     "start_time": "2021-01-10T19:05:40.596323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 4: One-hot encoding\n",
    "\n",
    "Use the next code cell to one-hot encode the data in `X_train` and `X_valid`.  Set the preprocessed DataFrames to `OH_X_train` and `OH_X_valid`, respectively.  \n",
    "- The full list of categorical columns in the dataset can be found in the Python list `object_cols`.\n",
    "- You should only one-hot encode the categorical columns in `low_cardinality_cols`.  All other categorical columns should be dropped from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:40.714146Z",
     "iopub.status.busy": "2021-01-10T19:05:40.713355Z",
     "iopub.status.idle": "2021-01-10T19:05:40.717304Z",
     "shell.execute_reply": "2021-01-10T19:05:40.716592Z"
    },
    "papermill": {
     "duration": 0.046443,
     "end_time": "2021-01-10T19:05:40.717450",
     "exception": false,
     "start_time": "2021-01-10T19:05:40.671007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_test = X_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:40.806772Z",
     "iopub.status.busy": "2021-01-10T19:05:40.803390Z",
     "iopub.status.idle": "2021-01-10T19:05:40.865613Z",
     "shell.execute_reply": "2021-01-10T19:05:40.865037Z"
    },
    "papermill": {
     "duration": 0.10948,
     "end_time": "2021-01-10T19:05:40.865737",
     "exception": false,
     "start_time": "2021-01-10T19:05:40.756257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 2, \"failureMessage\": \"`OH_X_train` should have 155 columns.\", \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"4_OneHot\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#cc3333\">Incorrect:</span> `OH_X_train` should have 155 columns."
      ],
      "text/plain": [
       "Incorrect: `OH_X_train` should have 155 columns."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One hot encode low cardinality columns\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "\n",
    "# Set column names that were removed\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "# Drop columns that are being replaced with one hot encodings\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "num_X_test = X_test.drop(object_cols, axis=1)\n",
    "\n",
    "# Concatenate dataframes of reduced train/val data with One Hot encodings\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "\n",
    "# Check your answer\n",
    "step_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:40.952540Z",
     "iopub.status.busy": "2021-01-10T19:05:40.951779Z",
     "iopub.status.idle": "2021-01-10T19:05:40.957621Z",
     "shell.execute_reply": "2021-01-10T19:05:40.956949Z"
    },
    "papermill": {
     "duration": 0.050629,
     "end_time": "2021-01-10T19:05:40.957756",
     "exception": false,
     "start_time": "2021-01-10T19:05:40.907127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_4.hint()\n",
    "#step_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040704,
     "end_time": "2021-01-10T19:05:41.039489",
     "exception": false,
     "start_time": "2021-01-10T19:05:40.998785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Run the next code cell to get the MAE for this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:41.130155Z",
     "iopub.status.busy": "2021-01-10T19:05:41.129387Z",
     "iopub.status.idle": "2021-01-10T19:05:42.739885Z",
     "shell.execute_reply": "2021-01-10T19:05:42.739166Z"
    },
    "papermill": {
     "duration": 1.658849,
     "end_time": "2021-01-10T19:05:42.740021",
     "exception": false,
     "start_time": "2021-01-10T19:05:41.081172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "18550.40561643836\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042403,
     "end_time": "2021-01-10T19:05:42.822561",
     "exception": false,
     "start_time": "2021-01-10T19:05:42.780158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate test predictions and submit your results\n",
    "\n",
    "After you complete Step 4, if you'd like to use what you've learned to submit your results to the leaderboard, you'll need to preprocess the test data before generating predictions.\n",
    "\n",
    "**This step is completely optional, and you do not need to submit results to the leaderboard to successfully complete the exercise.**\n",
    "\n",
    "Check out the previous exercise if you need help with remembering how to [join the competition](https://www.kaggle.com/c/home-data-for-ml-course) or save your results to CSV.  Once you have generated a file with your results, follow the instructions below:\n",
    "1. Begin by clicking on the blue **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n",
    "2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n",
    "3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n",
    "4. Click on the **Output** tab on the right of the screen.  Then, click on the file you would like to submit, and click on the blue **Submit** button to submit your results to the leaderboard.\n",
    "\n",
    "You have now successfully submitted to the competition!\n",
    "\n",
    "If you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T19:05:42.914658Z",
     "iopub.status.busy": "2021-01-10T19:05:42.913966Z",
     "iopub.status.idle": "2021-01-10T19:05:44.952775Z",
     "shell.execute_reply": "2021-01-10T19:05:44.953512Z"
    },
    "papermill": {
     "duration": 2.091207,
     "end_time": "2021-01-10T19:05:44.953693",
     "exception": false,
     "start_time": "2021-01-10T19:05:42.862486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (Optional) Your code here\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(OH_X_train, y_train)\n",
    "preds = model.predict(OH_X_test)\n",
    "\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041788,
     "end_time": "2021-01-10T19:05:45.036876",
     "exception": false,
     "start_time": "2021-01-10T19:05:44.995088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keep going\n",
    "\n",
    "With missing value handling and categorical encoding, your modeling process is getting complex. This complexity gets worse when you want to save your model to use in the future. The key to managing this complexity is something called **pipelines**. \n",
    "\n",
    "**[Learn to use pipelines](https://www.kaggle.com/alexisbcook/pipelines)** to preprocess datasets with categorical variables, missing values and any other messiness your data throws at you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041668,
     "end_time": "2021-01-10T19:05:45.119140",
     "exception": false,
     "start_time": "2021-01-10T19:05:45.077472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161289) to chat with other Learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 15.951519,
   "end_time": "2021-01-10T19:05:45.270000",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-10T19:05:29.318481",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
